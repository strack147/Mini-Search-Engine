The content of web pages typically consists of text, images, hyperlinks, etc. The search mechanisms in Internet content-based sites and become smarter as many accessing pages. 

In this exercise you are asked to develop a rudimentary reverse indexing mechanism, ie an application in the Java programming language to read format (.txt) files from a path on your computer (the path should be easily given by the examiner) and recognize all the different words contained in the records. These files will only contain text from websites in human readable format (detail contain words, spaces and symbols dot and comma).

You seek using Tree data structure to store effectively the different words that you have identified in text files as well as any of your statistical information is essential.  

Finally we should display in descending alphabetical order, by line, the words you locate the files that you have read, the frequency and the likelihood of their occurrence (consider that the application is not case sensitive). 

For example: If we had www.page1.txt files, www.page2.txt, www.page3.txt content respectively "Hi George", "Nick" and "Hi Anna and Annabel" the tree would have the following form (in parentheses capture the plurality of occurrences of those words). 

Optimize to remember the texts (files) into which keywords appear.  

After the application should be capable (through appropriate statistical calculations) allowing a motion of the user 
(combination of HomeFree) show us descending the name of the most relevant records, then the less relevant etc.  

For example, a user searching the expression "Hi and" you must first display the www.page3.txt file and then www.page1.txt as the first file also two words and the second file shows only one word. 

Important role the results ranking will play the existence of keywords in the records and the number of hits these words within files.
